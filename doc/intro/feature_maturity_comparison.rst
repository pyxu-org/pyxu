.. list-table:: Feature Maturity - Comparison
    :header-rows: 1
    :stub-columns: 1
    :widths: auto

    * - Package Name ğŸ“¦
      - Operator Types ğŸ› ï¸
      - Operator Algebra ğŸ¯
      - Algorithmic Suite ğŸ“š
      - Application Focus ğŸ¯
      - Remarks ğŸ’¬

    * - PyLops
      - ğŸ”´ Linear oeprators
      - ğŸŸ¡ Partial
      - ğŸ”´ Least-squares & sparse reconstructions
      - ğŸŸ¡ Wave-processing, geophysics
      - ğŸ”´ Linear operators based on NumPy's old matrix interface

    * - PyProximal
      - ğŸ”´ Proximable functionals
      - ğŸ”´ None
      - ğŸ”´ Non-smooth convex optimization
      - ğŸŸ¢ None
      - ğŸ”´ Under early development, unstable API

    * - Operator Discretization Library (ODL)
      - ğŸŸ¡ Linear operators, differentiable/proximable functionals
      - ğŸŸ¢ Full
      - ğŸŸ¡ Smooth & non-smooth convex optimization
      - ğŸŸ¡ Tomography
      - ğŸ”´ Domain-specific language for mathematicians

    * - GlobalBioIm
      - ğŸŸ¢ (Non)linear operators, differentiable/proximable functionals
      - ğŸŸ¢ Full
      - ğŸŸ¢ Smooth, non-smooth & hybrid convex optimization
      - ğŸŸ¢ None
      - ğŸ”´ MATLAB-based, unlike most DL frameworks

    * - SigPy
      - ğŸŸ¡ Linear operators, proximable functionals
      - ğŸŸ¡ Partial
      - ğŸŸ¡ Smooth & non-smooth convex optimization
      - ğŸ”´ MRI
      - ğŸ”´ Very limited suite of operators, functionals, and algorithms

    * - SCICO
      - ğŸŸ¢ (Non)linear operators, differentiable/proximable functionals
      - ğŸŸ¢ Full
      - ğŸŸ¢ Smooth, non-smooth & hybrid (non-)convex optimization
      - ğŸŸ¢ None
      - ğŸŸ¡ JAX-based (pure functions only, no mutation, etc.)

    * - DeepInv
      - ğŸŸ¢ (Non)linear operators, differentiable/proximable functionals
      - ğŸŸ¡ Partial
      - ğŸŸ¢ Smooth, non-smooth & hybrid (non-)convex optimization
      - ğŸŸ¡ Deep Learning
      - ğŸŸ¡ PyTorch-based (lots of dependencies)

    * - Pyxu
      - ğŸŸ¢ (Non)linear operators, differentiable/proximable functionals
      - ğŸŸ¢ Full
      - ğŸŸ¢ Smooth, non-smooth & hybrid (non-)convex optimization
      - ğŸŸ¢ None
      - ğŸŸ¢ Very rich suite of operators, functionals, algorithms & HPC features