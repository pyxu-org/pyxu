{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0f4dbaa-b39b-4ed4-a326-32cebb0ee61d",
   "metadata": {},
   "source": [
    "# Operator Algebra Logic\n",
    "\n",
    "At the heart of Pyxu's microservice architecture is a powerful operator algebra logic allowing to create versatile and complex operators/functionals from fundamental building blocks. In this section, we'll guide you through how to create and manipulate operators to construct intricate functionals and mappings. By the end, you'll be an expert in leveraging the power of Pyxu's operator algebra!\n",
    "\n",
    "## Arithmetic Operations on Operators\n",
    "\n",
    "In Pyxu, you can use a variety of arithmetic operations to combine basic operators into more complex ones. Here are some simple but powerful commands you can use:\n",
    "\n",
    "```python\n",
    ">> op1 + op2  # Addition of two operators\n",
    ">> op1 * op2  # Composition of two operators\n",
    ">> op ** 3    # Exponentiation of an operator\n",
    ">> op.argscale(c)  # Dilation by a scalar 'c'\n",
    ">> op.argshift(x)  # Shifting by a vector 'x'\n",
    ">> 4 * op  # Scaling by a scalar\n",
    ">> op.T  # Transposing\n",
    "```\n",
    "\n",
    "### How Does it Work? ðŸ› ï¸\n",
    "\n",
    "Every time you perform an arithmetic operation, Pyxu automatically infers the output type based on the properties of the operators involved in the operation. This type inference is super convenient because it saves you from manual calculations! \n",
    "\n",
    "For example, Pyxu takes care of updating as needed methods like `apply()`, `jacobian()`, `grad()`, `prox()`, and `adjoint()` according to arithmetic rules. This means you can plug these composite operators directly into proximal gradient algorithms without sweating the details of implementing gradients or proximal steps.\n",
    "\n",
    "## Behind the Scenes: Arithmetic Rules\n",
    "\n",
    "For those who love to peek under the hood, Pyxu utilizes a set of arithmetic rules located in the `pyxu.abc.arithmetic` module:\n",
    "\n",
    "- `Rule`: The base class for all arithmetic rules.\n",
    "- `ScaleRule`: Handles scaling of operators by scalars.\n",
    "- `ArgScaleRule`: Manages the dilation of the arguments of operators.\n",
    "- `ArgShiftRule`: Takes care of shifting the arguments of operators.\n",
    "- `AddRule`: Manages the addition of two operators.\n",
    "- `ChainRule`: Deals with the composition of two operators.\n",
    "- `PowerRule`: Handles exponentiation of an operator.\n",
    "- `TransposeRule`: Takes care of transposing a linear operator.\n",
    "\n",
    "### Working Example ðŸŽ¯\n",
    "\n",
    "Consider the composition of a `DiffFunc` with a `DiffMap`. Let `f` be a `DiffFunc` and `L` be a `DiffMap`. Then their composition `h` is another `DiffFunc`, and the gradient is given by:\n",
    "\n",
    "```python\n",
    ">> h = f * L\n",
    ">> h.grad(x) = L.jacobian(x).adjoint(f.grad(L(x)))\n",
    "```\n",
    "\n",
    "More generally, here is how `ChainRule` updates the various core methods when a composition of the form `_lhs * _rhs` is performed:\n",
    "\n",
    "- `apply()` and `lipschitz`:\n",
    "    \n",
    "    ```python\n",
    "    op.apply(arr) = _lhs.apply(_rhs.apply(arr))\n",
    "    op.lipschitz = _lhs.lipschitz * _rhs.lipschitz\n",
    "    ```\n",
    "\n",
    "- `prox()`:\n",
    "\n",
    "    ```python\n",
    "    op.prox(arr, tau) = _rhs.adjoint(_lhs.prox(_rhs.apply(arr), tau))\n",
    "    ```\n",
    "\n",
    "- `jacobian()` and `diff_lipschitz`:\n",
    "\n",
    "    ```python\n",
    "    op.jacobian(arr) = _lhs.jacobian(_rhs.apply(arr)) * _rhs.jacobian(arr)\n",
    "    op.diff_lipschitz =\n",
    "        quadratic            => _quad_spec().Q.lipschitz\n",
    "        linear \\comp linear  => 0\n",
    "        linear \\comp diff    => _lhs.lipschitz * _rhs.diff_lipschitz\n",
    "        diff   \\comp linear  => _lhs.diff_lipschitz * (_rhs.lipschitz ** 2)\n",
    "        diff   \\comp diff    => \\infty\n",
    "    ```\n",
    "\n",
    "- `grad()`:\n",
    "\n",
    "    ```python\n",
    "    op.grad(arr) = _lhs.grad(_rhs.apply(arr)) @ _rhs.jacobian(arr).asarray()\n",
    "    ```\n",
    "\n",
    "## Building Block-Operators \n",
    "\n",
    "You can even define block-operators using the `coo_block` function. Alternatively, higher-level functions like `block`, `block_diag`, `stack`, `vstack`, and `hstack` can also be used.\n",
    "\n",
    "For example, the following code snippet: \n",
    "\n",
    "```python\n",
    ">> coo_block(([A(500,1000), B(1,1000), C(500,500), D(1,3)],  # data\n",
    "   ...      [[0, 1, 0, 2],  # i\n",
    "   ...       [0, 0, 2, 1],  # j\n",
    "            ]),grid_shape=(3, 3))\n",
    "```\n",
    "\n",
    "results in a block sparse composite operator of the form:\n",
    "\n",
    "| coarse_idx |      0       |    1    |      2      |\n",
    "|------------|--------------|---------|-------------|\n",
    "|          0 | A(500, 1000) |         | C(500, 500) |\n",
    "|          1 | B(1, 1000)   |         |             |\n",
    "|          2 |              | D(1, 3) |             |\n",
    "\n",
    "\n",
    "Similarly, a functional $h(x) = \\sum_{i=1}^{3} f_i(K_ix)$, can be constructed as follows:\n",
    "\n",
    "```python\n",
    "f = hstack([f_1, f_2, f_3]) * vstack([K_1, K_2, K_3])\n",
    "```\n",
    "\n",
    "Again, Pyxu takes care of all the heavy lifting by automatically inferring the output type and the methods and attributes of the block-operator from its building blocks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
